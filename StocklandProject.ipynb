{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stockland Project \n",
    "\n",
    "Visitation Predition based on weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data set \n",
    "### 1. Stockland Visitation dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset               8190\n",
       "Date                8190\n",
       "Count visitation    7050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(\"data/Stockland-Visitation-Data.csv\", encoding=None )\n",
    "df_1.head()\n",
    "df_1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Weather dataset (collected from BOM.gov.au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset              8190\n",
       "Date               8190\n",
       "Min temperature    8068\n",
       "Max temperature    8126\n",
       "Solar exposure     8186\n",
       "Rainfall           7886\n",
       "Raining period     5597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv(\"data/weather.csv\", encoding=None)\n",
    "df_2.head()\n",
    "df_2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging the Visitation dataset and Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset</th>\n",
       "      <th>Date</th>\n",
       "      <th>Count visitation</th>\n",
       "      <th>Min temperature</th>\n",
       "      <th>Max temperature</th>\n",
       "      <th>Solar exposure</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Raining period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>1/01/2021</td>\n",
       "      <td>11878.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>2/01/2021</td>\n",
       "      <td>7962.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>32.6</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>3/01/2021</td>\n",
       "      <td>12918.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>4/01/2021</td>\n",
       "      <td>12796.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>32.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>5/01/2021</td>\n",
       "      <td>13321.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>34.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Asset       Date  Count visitation  Min temperature  Max temperature  \\\n",
       "0  Baldivis  1/01/2021           11878.0             19.9             30.0   \n",
       "1  Baldivis  2/01/2021            7962.0             19.5             32.6   \n",
       "2  Baldivis  3/01/2021           12918.0             18.0             32.0   \n",
       "3  Baldivis  4/01/2021           12796.0             17.3             32.7   \n",
       "4  Baldivis  5/01/2021           13321.0             18.2             34.2   \n",
       "\n",
       "   Solar exposure  Rainfall   Raining period  \n",
       "0            30.7        0.0             NaN  \n",
       "1            30.2        0.0             NaN  \n",
       "2            24.3        0.0             NaN  \n",
       "3            30.9        0.0             NaN  \n",
       "4            30.8        0.0             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.merge(df_1, df_2, on = ['Asset','Date'], how = \"inner\")\n",
    "df_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[\"Solar exposure\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset               8190\n",
       "Date                8190\n",
       "Count visitation    7050\n",
       "Min temperature     8068\n",
       "Max temperature     8126\n",
       "Solar exposure      8186\n",
       "Rainfall            7886\n",
       "Raining period      5597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "### Filling missing values\n",
    "\n",
    "After merge the two dataset, we observe that there are missing values in the data provided, which probably causing from they way data is collected. To resolve this problem, we apply a quick cleaning that run and check over all the missing values, and then imputing them with approriate value so that we can pulling them all into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset                  0\n",
       "Date                   0\n",
       "Count visitation    1140\n",
       "Min temperature      122\n",
       "Max temperature       64\n",
       "Solar exposure         4\n",
       "Rainfall             304\n",
       "Raining period      2593\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check na and missing values\n",
    "df_full.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing data for rainfall and rain period: \n",
    "For rainfall, if there is a missing value, we assume that the rainfall is 0 (no rain). \n",
    "By looking at the raining period columns in the dataset collected from BOM, we define the backward and forward fill as the approriate method to impute missing value of the weather data, including Raining Period, Temperatures and Solar Exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing rainfall missing data with 0\n",
    "df_full['Rainfall ']=df_full['Rainfall '].fillna(0)\n",
    "# we use backwards fill for raining period \n",
    "df_full['Raining period']= df_full['Raining period'].bfill()\n",
    "# if rainfall in a day is 0, then the raining period is 0\n",
    "for i in range(len(df_full)):\n",
    "    if df_full['Rainfall '].loc[i]==0:\n",
    "        df_full['Raining period'].loc[i]=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use forward fill to impute missing values of min temperature, max temperature and solar exposure\n",
    "df_full['Max temperature']=df_full['Max temperature'].ffill()\n",
    "df_full['Min temperature']=df_full['Min temperature'].ffill()\n",
    "df_full['Solar exposure']=df_full['Solar exposure'].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummies variable for Assets and month \n",
    "Assets and months are considered as nominal categorical variables, so that one-hot encoding will be used for creating dummies variable (taking values of 1 or 0 to stand for true and false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummies variables for Location (Asset)\n",
    "df_full = pd.get_dummies(df_full,columns=['Asset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hungn\\AppData\\Local\\Temp\\ipykernel_22860\\2109046020.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['Date'].loc[i]= datetime.strptime(df_full['Date'].loc[i],'%d/%m/%Y')\n",
      "C:\\Users\\hungn\\AppData\\Local\\Temp\\ipykernel_22860\\2109046020.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['Month'].loc[i]=df_full['Date'].loc[i].month\n"
     ]
    }
   ],
   "source": [
    "## Extract month variable\n",
    "from datetime import datetime \n",
    "for i in range(len(df_full)):   \n",
    "    df_full['Date'].loc[i]= datetime.strptime(df_full['Date'].loc[i],'%d/%m/%Y')\n",
    "\n",
    "df_full['Date'].loc[1].month\n",
    "df_full['Month']= \"\"\n",
    "for i in range(len(df_full)):\n",
    "    df_full['Month'].loc[i]=df_full['Date'].loc[i].month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into categorical month\n",
    "df_full['Month']= df_full['Month'].astype(str)\n",
    "df_full = pd.get_dummies(df_full,columns=['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows containing missing data in visitation\n",
    "df_clean = df_full[df_full['Count visitation'].notna() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiiting models \n",
    "### Prepare Model Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_clean =shuffle(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "y_train = df_clean['Count visitation']\n",
    "X_train = df_clean.drop(columns = ['Count visitation', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fitting Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 11002217.410\n",
      "R^2 train: 0.794\n",
      "CV accuracy scores\n",
      " [[0.73596457]\n",
      " [0.80490426]\n",
      " [0.80041495]\n",
      " [0.7803289 ]\n",
      " [0.8260849 ]\n",
      " [0.78273984]\n",
      " [0.77316103]\n",
      " [0.79391698]\n",
      " [0.81338186]\n",
      " [0.80788672]]\n",
      "CV accuracy: 0.792 +/- 0.024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')\n",
    "\n",
    "scores_lr = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 130427.133\n",
      "R^2 train: 0.998\n",
      "CV accuracy scores\n",
      " [[0.51779299]\n",
      " [0.60522393]\n",
      " [0.62500164]\n",
      " [0.65491861]\n",
      " [0.68639198]\n",
      " [0.58041772]\n",
      " [0.60336682]\n",
      " [0.66638931]\n",
      " [0.58792506]\n",
      " [0.61826939]]\n",
      "CV accuracy: 0.615 +/- 0.046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=30)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree.predict(X_train)\n",
    "\n",
    "print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')\n",
    "\n",
    "scores_lr = cross_val_score(estimator=tree, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Random Forrest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 1558859.344\n",
      "R^2 train: 0.971\n",
      "CV accuracy scores\n",
      " [[0.74091284]\n",
      " [0.78921678]\n",
      " [0.8095057 ]\n",
      " [0.78889448]\n",
      " [0.81652837]\n",
      " [0.78887427]\n",
      " [0.7859544 ]\n",
      " [0.80175755]\n",
      " [0.78950755]\n",
      " [0.7905529 ]]\n",
      "CV accuracy: 0.790 +/- 0.019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = forest.predict(X_train)\n",
    "\n",
    "print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')\n",
    "\n",
    "scores_lr = cross_val_score(estimator=forest, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Base on the above result, we will select the model with the highest accuracy score and $R^2$ value, which is the Random Forest Regressor.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyper Parameter Tuning For Selected Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 150, 200, 250], 'max_features': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'bootstrap': [True, False]}\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_features': 11, 'max_depth': 20, 'bootstrap': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in range(50,300,50)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in range(4,22)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "              'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 10 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=1, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "# Ouput the best params\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 train: 0.950\n"
     ]
    }
   ],
   "source": [
    "# final = RandomForestRegressor(n_estimators= 200, max_features= 7, max_depth= 30, bootstrap= False)\n",
    "# final.fit(X_train, y_train)\n",
    "\n",
    "final = RandomForestRegressor(n_estimators= 250, max_features= 11, max_depth= 20, bootstrap= True)\n",
    "final.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = final.predict(X_train)\n",
    "\n",
    "#print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores\n",
      " [[0.7488358 ]\n",
      " [0.80083235]\n",
      " [0.81734921]\n",
      " [0.80034745]\n",
      " [0.83310278]\n",
      " [0.7994712 ]\n",
      " [0.79500923]\n",
      " [0.80739552]\n",
      " [0.80318788]\n",
      " [0.80388987]]\n",
      "CV accuracy: 0.801 +/- 0.020\n"
     ]
    }
   ],
   "source": [
    "scores_lr = cross_val_score(estimator=final, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "# print(scores_v2)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
